{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    ToTensor()\n",
       "    Normalize(mean=0.5, std=0.5)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transforms = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5), (0.5))]\n",
    ")\n",
    "transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=0.5, std=0.5)\n",
       "           )"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "dataset = datasets.MNIST(root=\"data\", transform=transforms, download=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x23713a71570>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=32, shuffle=True)\n",
    "dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, image_dim) -> None:\n",
    "        super().__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Linear(in_features=image_dim, out_features=128),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Linear(in_features=128, out_features=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, image_dim) -> None:\n",
    "        super().__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(in_features=z_dim, out_features=256),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Linear(in_features=256, out_features=image_dim),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-4\n",
    "z_dim = 64\n",
    "image_dim = 28 * 28 * 1\n",
    "batch_size = 32\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator(image_dim=image_dim).to(device=device)\n",
    "generator = Generator(z_dim=z_dim, image_dim=image_dim).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise = torch.randn((batch_size, z_dim)).to(device=device)\n",
    "optimizer_generator = torch.optim.Adam(generator.parameters(), lr=lr)\n",
    "optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
    "loss_fn = nn.BCELoss()\n",
    "fake_writer = SummaryWriter(f\"logs/fake\")\n",
    "real_writer = SummaryWriter(f\"logs/real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0\n",
    "for epoch in range(epochs):\n",
    "    for i, (real, _) in enumerate(dataloader):\n",
    "        real = real.view(-1, 784).to(device=device)\n",
    "        batch_size = real.shape[0]\n",
    "        ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n",
    "        noise = torch.randn(batch_size, z_dim).to(device=device)\n",
    "        fake = generator(noise)\n",
    "        real_discriminator = discriminator(real).view(-1)\n",
    "        real_discriminator_loss = loss_fn(\n",
    "            real_discriminator, torch.ones_like(real_discriminator)\n",
    "        )\n",
    "        fake_discriminator = discriminator(fake).view(-1)\n",
    "        fake_discriminator_loss = loss_fn(\n",
    "            fake_discriminator, torch.ones_like(fake_discriminator)\n",
    "        )\n",
    "        discriminator_loss = (real_discriminator_loss + fake_discriminator_loss) / 2\n",
    "        discriminator.zero_grad()\n",
    "        discriminator_loss.backward(retain_graph=True)\n",
    "        optimizer_discriminator.step()\n",
    "        ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n",
    "        output = discriminator(fake).view(-1)\n",
    "        generator_loss = loss_fn(output, torch.ones_like(output))\n",
    "        generator.zero_grad()\n",
    "        generator_loss.backward()\n",
    "        optimizer_generator.step()\n",
    "        if i == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{epochs}] Batch {i}/{len(dataloader)} \\\n",
    "                      Discriminator Loss: {discriminator_loss:.4f}, Generator Loss: {generator_loss:.4f}\"\n",
    "            )\n",
    "            with torch.no_grad():\n",
    "                fake = generator(fixed_noise).reshape(-1, 1, 28, 28)\n",
    "                data = real.reshape(-1, 1, 28, 28)\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake, normalize=True)\n",
    "                img_grid_real = torchvision.utils.make_grid(data, normalize=True)\n",
    "                fake_writer.add_image(\n",
    "                    \"Mnist Fake Images\", img_grid_fake, global_step=step\n",
    "                )\n",
    "                real_writer.add_image(\n",
    "                    \"Mnist Real Images\", img_grid_real, global_step=step\n",
    "                )\n",
    "                step += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
